{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfk7bUq4gZlEoqcipua96g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andr3w1699/Intelligent_System_for_Pattern_Recognition/blob/main/SecondAssignement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second assignement ISPR: ANDREA LEPORI\n",
        "\n",
        "Selected assignement:\n",
        "\n",
        "Assignment 3\n",
        "\n",
        "Implement from scratch an RBM and apply it to DSET2. The RBM should be implemented fully by you (both training and inference steps) but you are free to use library functions for the rest (e.g. image loading and management, etc.). Implement a generalization of the Contrastive Divergence (CD) learning algorithm that defines the number of steps K of the Gibbs sampling Markov chain runned before collecting the samples to estimate the model expectation. For instance the standard CD learning would be obtained with K=1. Test your models by training two versions of them, one with a small K and one with a medium K (I suggest you do not go over 10 steps), and discuss the differences in performance/behaviour (if any).\n",
        "\n",
        "Outline of the assigment:\n",
        "\n",
        "1.     Train an RBM with a number of hidden neurons selected by you (single layer) on the MNIST data (use the training set split provided by the website) using CD(K) with two choices of K.\n",
        "\n",
        "2.     Use the trained RBMs to encode a selection of test images (e.g. using one per digit type) using the corresponding activation of the hidden neurons.\n",
        "\n",
        "3.    Train a simple classifier (e.g. any simple classifier in scikit) to recognize the MNIST digits using as inputs their encoding obtained at step 2. Use the standard training/test split. Show a performance metric of your choice in the presentation/handout and use it to confront the two versions of the RBM (obtained with different K).\n",
        "\n",
        "Dataset:\n",
        "DSET2 (Image processing: MNIST): (https://www.kaggle.com/datasets/hojjatk/mnist-dataset) or (https://huggingface.co/datasets/ylecun/mnist/) or (http://yann.lecun.com/exdb/mnist/)\n"
      ],
      "metadata": {
        "id": "FPbnAkWzQllX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pcm9bECQf2H",
        "outputId": "5a31e27b-e784-4960-9a1c-9a7c56d92b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy torch scikit-learn matplotlib torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2sfKIgi-SkBQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST Dataset\n",
        "\n",
        "# This defines how each image in the dataset should be preprocessed before being used.\n",
        "# transforms.ToTensor() converts each image (which is in PIL Image format) into a PyTorch tensor with values scaled between 0 and 1.\n",
        "# transforms.Compose([...]) lets you chain multiple transforms together, though here weâ€™re just using one (ToTensor()).\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# download and store the training and test portion of the MNIST dataset\n",
        "# The dataset will be stored in a folder called data in your project directory.\n",
        "# train=True --> training, train=False --> test set.\n",
        "# download=True: Downloads the dataset automatically if it's not already there.\n",
        "# transform=transform: Applies the ToTensor() transform to each image when it's loaded.\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Wraps the dataset in a DataLoader, which is an iterator that loads the data in batches.\n",
        "# batch_size=64: Each time you ask for a batch, it gives you 64 images (and their labels).\n",
        "# shuffle=True: Randomly shuffles the dataset each epoch, which helps make training more effective (less bias from order).\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "# same idea, but for the test set, fetches larger batches for faster evaluation (you don't need to update weights during testing).\n",
        "# shuffle=False: We donâ€™t shuffle the test set â€” itâ€™s okay to evaluate in order.\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n"
      ],
      "metadata": {
        "id": "j578aQCGTTKH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one batch from the train_loader\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show the shape\n",
        "print(f\"Batch shape: {images.shape}\")      # (batch_size, 1, 28, 28)\n",
        "print(f\"Label shape: {labels.shape}\")      # (batch_size,)\n",
        "\n",
        "# Show the first 6 images with labels\n",
        "fig, axes = plt.subplots(1, 6, figsize=(12, 2))\n",
        "for i in range(6):\n",
        "    img = images[i].squeeze()  # Remove channel dimension (1,28,28) -> (28,28)\n",
        "    label = labels[i].item()\n",
        "    axes[i].imshow(img, cmap='gray')\n",
        "    axes[i].set_title(f\"Label: {label}\")\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "3uhYVMIPVpgR",
        "outputId": "3d136121-99a2-4414-dc83-81077ad4ed92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([64, 1, 28, 28])\n",
            "Label shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x200 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding image representation:\n",
        "\n",
        "`images.shape` â†’ `(64, 1, 28, 28)`\n",
        "\n",
        "*   64 images in this batch\n",
        "*   Each image has 1 channel (grayscale)\n",
        "*   Each image is 28x28 pixels\n",
        "*   Pixel values are in the range [0, 1] (because of ToTensor())\n",
        "*   Each image is stored as a PyTorch tensor\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-TeJfOyyWGMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to see the raw tensor (pixel values):\n",
        "print(images[0])               # Tensor of shape (1, 28, 28)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOL4zmOLWnu3",
        "outputId": "dd717590-6d1d-4479-b73d-f93fff1d0682"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.6902, 0.6392, 0.6392,\n",
            "          0.6431, 0.6392, 0.6392, 0.7961, 0.9961, 0.8745, 0.9961, 0.9961,\n",
            "          0.9961, 0.8706, 0.2314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.6000, 0.9647, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9176,\n",
            "          0.9961, 0.9961, 0.9529, 0.3922, 0.0314, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3020, 0.6588, 0.9451,\n",
            "          0.6235, 0.4980, 0.4980, 0.4745, 0.1412, 0.1412, 0.1412, 0.0902,\n",
            "          0.5569, 0.9961, 0.9961, 0.9961, 0.1412, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.1373,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
            "          0.8745, 0.9961, 0.9961, 0.6706, 0.0314, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1451,\n",
            "          0.9961, 0.9961, 0.9961, 0.2980, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7294,\n",
            "          0.9961, 0.9961, 0.4902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.9843,\n",
            "          0.9961, 0.9961, 0.2824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3961, 0.9961,\n",
            "          0.9961, 0.7647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8510, 0.9961,\n",
            "          0.9882, 0.2627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0275, 0.1020, 0.0000, 0.9255, 0.9961,\n",
            "          0.6667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.6588, 0.9961, 0.7725, 0.9725, 0.9961,\n",
            "          0.8000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.5020, 0.9961, 1.0000, 0.9961, 0.9961,\n",
            "          0.8118, 0.4706, 0.2157, 0.1686, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0118, 0.1412, 0.3882, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.9961, 0.9647, 0.7529, 0.4157, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.9961, 0.9961,\n",
            "          0.9373, 0.5647, 0.4706, 0.2118, 0.1373, 0.1216, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.9961, 0.9961,\n",
            "          0.4431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2902, 0.9961, 0.9961,\n",
            "          0.2118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.9961, 0.8627,\n",
            "          0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.9961, 0.5451,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5647, 0.9961, 0.3451,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5137, 0.7137, 0.0431,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(images[0][0])            # First channel (since it's grayscale, just one)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaK9qehWXVFI",
        "outputId": "871db863-bbf7-4a07-ecf5-b256ed403180"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.6902, 0.6392, 0.6392, 0.6431,\n",
            "         0.6392, 0.6392, 0.7961, 0.9961, 0.8745, 0.9961, 0.9961, 0.9961, 0.8706,\n",
            "         0.2314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.6000, 0.9647, 0.9961, 0.9961, 0.9961,\n",
            "         0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9176, 0.9961, 0.9961,\n",
            "         0.9529, 0.3922, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3020, 0.6588, 0.9451, 0.6235,\n",
            "         0.4980, 0.4980, 0.4745, 0.1412, 0.1412, 0.1412, 0.0902, 0.5569, 0.9961,\n",
            "         0.9961, 0.9961, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.1373, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.8745, 0.9961,\n",
            "         0.9961, 0.6706, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1451, 0.9961, 0.9961,\n",
            "         0.9961, 0.2980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7294, 0.9961, 0.9961,\n",
            "         0.4902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.9843, 0.9961, 0.9961,\n",
            "         0.2824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3961, 0.9961, 0.9961, 0.7647,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8510, 0.9961, 0.9882, 0.2627,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0275, 0.1020, 0.0000, 0.9255, 0.9961, 0.6667, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.6588, 0.9961, 0.7725, 0.9725, 0.9961, 0.8000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.5020, 0.9961, 1.0000, 0.9961, 0.9961, 0.8118, 0.4706,\n",
            "         0.2157, 0.1686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0118, 0.1412, 0.3882, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "         0.9961, 0.9647, 0.7529, 0.4157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.9961, 0.9961, 0.9373, 0.5647,\n",
            "         0.4706, 0.2118, 0.1373, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.9961, 0.9961, 0.4431, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.2902, 0.9961, 0.9961, 0.2118, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.9961, 0.8627, 0.0157, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.9961, 0.5451, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.5647, 0.9961, 0.3451, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.5137, 0.7137, 0.0431, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(images[0][0][:5, :5])    # Top-left 5x5 corner pixel values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CiwgOkLXrE8",
        "outputId": "1c774ccd-6ce1-496f-e1be-ef809f72fedb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RBM Implementation (from scratch)"
      ],
      "metadata": {
        "id": "PqT1spMNX0Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RBM:\n",
        "  def __init__(self, n_visible, n_hidden, k=1, learning_rate=0.1):\n",
        "    # number of input neurons (in MNIST pixels of an image --> 28x28 = 784)\n",
        "    self.n_visible = n_visible\n",
        "    # number of hidden units (it's an hyperparameter)\n",
        "    self.n_hidden = n_hidden\n",
        "    # number of Gibbs sampling steps for Contrastive Divergence (CD-k).\n",
        "    self.k = k\n",
        "    # step size for updating the weights and biases.\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "    # W is the weight matrix connecting visible to hidden units.\n",
        "    # Shape = n_hidden x n_visible. Initialized to Random small values\n",
        "    self.W = torch.randn(n_hidden, n_visible) * 0.01  # weight matrix\n",
        "    self.h_bias = torch.zeros(n_hidden)               # hidden bias\n",
        "    self.v_bias = torch.zeros(n_visible)              # visible bias\n",
        "\n",
        "\n",
        "  # Sample hidden units given visible units\n",
        "  # params: v is a batch of visible units\n",
        "  def sample_h(self, v):\n",
        "        # computes wx that is the weighthed sum + bias for hidden units\n",
        "        wx = torch.matmul(v, self.W.t()) + self.h_bias\n",
        "        # computes probability of activation\n",
        "        prob = torch.sigmoid(wx)\n",
        "        # returns probabilities and sampled binary activations (0 or 1)\n",
        "        return prob, torch.bernoulli(prob)\n",
        "\n",
        "  # Sample visible units given hidden units\n",
        "  # Reverse of sample_h. Given hidden units, reconstruct visible units\n",
        "  # Returns probabilities + samples for visible layer\n",
        "  def sample_v(self, h):\n",
        "        wx = torch.matmul(h, self.W) + self.v_bias\n",
        "        prob = torch.sigmoid(wx)\n",
        "        return prob, torch.bernoulli(prob)\n",
        "\n",
        "  def contrastive_divergence(self, v0):\n",
        "        # start with input v0 (original data/training example)\n",
        "        v = v0\n",
        "        # run k steps of Gibbs sampling\n",
        "        # sample h from v, then v from h, repeatedly\n",
        "        # this gives the model's approximation of the input data (its \"fantasy\" or \"dream\")\n",
        "        for _ in range(self.k):\n",
        "            ph, h = self.sample_h(v)\n",
        "            pv, v = self.sample_v(h)\n",
        "\n",
        "        # Positive and negative phases\n",
        "        # positive phase: compute hidden activations from original input\n",
        "        ph0, h0 = self.sample_h(v0)\n",
        "        # negative phase: compute hidden activations from model-generated (sampled) input after k steps.\n",
        "        phk, hk = self.sample_h(v)\n",
        "\n",
        "        # Update weights and biases using the difference between positive and negative phases\n",
        "        # intuition: update weights and biases using the difference between positive and negative phases\n",
        "        self.W += self.learning_rate * (torch.matmul(h0.t(), v0) - torch.matmul(hk.t(), v))\n",
        "        self.v_bias += self.learning_rate * torch.sum(v0 - v, dim=0)\n",
        "        self.h_bias += self.learning_rate * torch.sum(h0 - hk, dim=0)\n",
        "\n",
        "\n",
        "  def train(self, train_loader, n_epochs=5):\n",
        "    for epoch in range(n_epochs):\n",
        "        loss = 0\n",
        "        for images, _ in train_loader:\n",
        "            images = images.view(-1, self.n_visible)\n",
        "            images = (images > 0.5).float()\n",
        "            self.contrastive_divergence(images)\n",
        "            loss += torch.mean((images - self.reconstruct(images)) ** 2).item()\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {loss / len(train_loader)}\")\n",
        "\n",
        "  def reconstruct(self, v):\n",
        "      prob_h, h = self.sample_h(v)\n",
        "      prob_v, v_sample = self.sample_v(prob_h)\n",
        "      return prob_v\n",
        "\n",
        "  def encode(self, v):\n",
        "      prob_h, _ = self.sample_h(v)\n",
        "      return prob_h"
      ],
      "metadata": {
        "id": "WSLlckAEX_mg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_visible = 28 * 28\n",
        "n_hidden = 128\n",
        "\n",
        "# RBM with K=1\n",
        "rbm_k1 = RBM(n_visible=n_visible, n_hidden=n_hidden, k=1)\n",
        "rbm_k1.train(train_loader, n_epochs=5)\n",
        "\n",
        "# RBM with K=5\n",
        "rbm_k5 = RBM(n_visible=n_visible, n_hidden=n_hidden, k=5)\n",
        "rbm_k5.train(train_loader, n_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_Wuo70diSBR",
        "outputId": "bc67fa94-37fb-44c9-cd4c-47f9a8e29f04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.07476613009725806\n",
            "Epoch 2, Loss: 0.06886266160414799\n",
            "Epoch 3, Loss: 0.06632272290316091\n",
            "Epoch 4, Loss: 0.06398941176548315\n",
            "Epoch 5, Loss: 0.06343364605564934\n",
            "Epoch 1, Loss: 0.0809753204046536\n",
            "Epoch 2, Loss: 0.07416447404541694\n",
            "Epoch 3, Loss: 0.07279803764337162\n",
            "Epoch 4, Loss: 0.0729471289002692\n",
            "Epoch 5, Loss: 0.07289666793684461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_encoded_features(rbm, data_loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader:\n",
        "            images = images.view(-1, 28*28)\n",
        "            images = (images > 0.5).float()\n",
        "            encoded = rbm.encode(images)\n",
        "            features.append(encoded.numpy())\n",
        "            labels.append(targets.numpy())\n",
        "    return np.vstack(features), np.hstack(labels)\n",
        "\n",
        "X_train_k1, y_train = get_encoded_features(rbm_k1, train_loader)\n",
        "X_test_k1, y_test = get_encoded_features(rbm_k1, test_loader)\n",
        "\n",
        "X_train_k5, _ = get_encoded_features(rbm_k5, train_loader)\n",
        "X_test_k5, _ = get_encoded_features(rbm_k5, test_loader)"
      ],
      "metadata": {
        "id": "t5nexA02sYx5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_k1 = LogisticRegression(max_iter=1000)\n",
        "clf_k1.fit(X_train_k1, y_train)\n",
        "pred_k1 = clf_k1.predict(X_test_k1)\n",
        "acc_k1 = accuracy_score(y_test, pred_k1)\n",
        "\n",
        "clf_k5 = LogisticRegression(max_iter=1000)\n",
        "clf_k5.fit(X_train_k5, y_train)\n",
        "pred_k5 = clf_k5.predict(X_test_k5)\n",
        "acc_k5 = accuracy_score(y_test, pred_k5)\n",
        "\n",
        "print(f\"Accuracy with K=1: {acc_k1 * 100:.2f}%\")\n",
        "print(f\"Accuracy with K=5: {acc_k5 * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "fVhsI0_Bsf-Z",
        "outputId": "32075a10-6b81-492c-d342-b0820c8c5aca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with K=1: 67.49%\n",
            "Accuracy with K=5: 11.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(['K=1', 'K=5'], [acc_k1, acc_k5])\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Classifier accuracy for different CD(K) values\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b9TxVGz1spy5",
        "outputId": "d465445f-0e21-4fd4-a512-a07797ec7be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}