{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsbydhUsIVNhjJQYyFLkv8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andr3w1699/Intelligent_System_for_Pattern_Recognition/blob/main/SecondAssignement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second assignement ISPR: ANDREA LEPORI\n",
        "\n",
        "Selected assignement:\n",
        "\n",
        "Assignment 3\n",
        "\n",
        "Implement from scratch an RBM and apply it to DSET2. The RBM should be implemented fully by you (both training and inference steps) but you are free to use library functions for the rest (e.g. image loading and management, etc.). Implement a generalization of the Contrastive Divergence (CD) learning algorithm that defines the number of steps K of the Gibbs sampling Markov chain runned before collecting the samples to estimate the model expectation. For instance the standard CD learning would be obtained with K=1. Test your models by training two versions of them, one with a small K and one with a medium K (I suggest you do not go over 10 steps), and discuss the differences in performance/behaviour (if any).\n",
        "\n",
        "Outline of the assigment:\n",
        "\n",
        "1.     Train an RBM with a number of hidden neurons selected by you (single layer) on the MNIST data (use the training set split provided by the website) using CD(K) with two choices of K.\n",
        "\n",
        "2.     Use the trained RBMs to encode a selection of test images (e.g. using one per digit type) using the corresponding activation of the hidden neurons.\n",
        "\n",
        "3.    Train a simple classifier (e.g. any simple classifier in scikit) to recognize the MNIST digits using as inputs their encoding obtained at step 2. Use the standard training/test split. Show a performance metric of your choice in the presentation/handout and use it to confront the two versions of the RBM (obtained with different K).\n",
        "\n",
        "Dataset:\n",
        "DSET2 (Image processing: MNIST): (https://www.kaggle.com/datasets/hojjatk/mnist-dataset) or (https://huggingface.co/datasets/ylecun/mnist/) or (http://yann.lecun.com/exdb/mnist/)\n"
      ],
      "metadata": {
        "id": "FPbnAkWzQllX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Pcm9bECQf2H"
      },
      "outputs": [],
      "source": [
        "!pip install numpy torch scikit-learn matplotlib torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "2sfKIgi-SkBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST Dataset\n",
        "\n",
        "# This defines how each image in the dataset should be preprocessed before being used.\n",
        "# transforms.ToTensor() converts each image (which is in PIL Image format) into a PyTorch tensor with values scaled between 0 and 1.\n",
        "# transforms.Compose([...]) lets you chain multiple transforms together, though here we’re just using one (ToTensor()).\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# download and store the training and test portion of the MNIST dataset\n",
        "# The dataset will be stored in a folder called data in your project directory.\n",
        "# train=True --> training, train=False --> test set.\n",
        "# download=True: Downloads the dataset automatically if it's not already there.\n",
        "# transform=transform: Applies the ToTensor() transform to each image when it's loaded.\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Wraps the dataset in a DataLoader, which is an iterator that loads the data in batches.\n",
        "# batch_size=64: Each time you ask for a batch, it gives you 64 images (and their labels).\n",
        "# shuffle=True: Randomly shuffles the dataset each epoch, which helps make training more effective (less bias from order).\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "# same idea, but for the test set, fetches larger batches for faster evaluation (you don't need to update weights during testing).\n",
        "# shuffle=False: We don’t shuffle the test set — it’s okay to evaluate in order.\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n"
      ],
      "metadata": {
        "id": "j578aQCGTTKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one batch from the train_loader\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show the shape\n",
        "print(f\"Batch shape: {images.shape}\")      # (batch_size, 1, 28, 28)\n",
        "print(f\"Label shape: {labels.shape}\")      # (batch_size,)\n",
        "\n",
        "# Show the first 6 images with labels\n",
        "fig, axes = plt.subplots(1, 6, figsize=(12, 2))\n",
        "for i in range(6):\n",
        "    img = images[i].squeeze()  # Remove channel dimension (1,28,28) -> (28,28)\n",
        "    label = labels[i].item()\n",
        "    axes[i].imshow(img, cmap='gray')\n",
        "    axes[i].set_title(f\"Label: {label}\")\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3uhYVMIPVpgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding image representation:\n",
        "\n",
        "`images.shape` → `(64, 1, 28, 28)`\n",
        "\n",
        "*   64 images in this batch\n",
        "*   Each image has 1 channel (grayscale)\n",
        "*   Each image is 28x28 pixels\n",
        "*   Pixel values are in the range [0, 1] (because of ToTensor())\n",
        "*   Each image is stored as a PyTorch tensor\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-TeJfOyyWGMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to see the raw tensor (pixel values):\n",
        "print(images[0])               # Tensor of shape (1, 28, 28)"
      ],
      "metadata": {
        "id": "dOL4zmOLWnu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(images[0][0])            # First channel (since it's grayscale, just one)"
      ],
      "metadata": {
        "id": "NaK9qehWXVFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(images[0][0][:5, :5])    # Top-left 5x5 corner pixel values"
      ],
      "metadata": {
        "id": "1CiwgOkLXrE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RBM Implementation (from scratch)"
      ],
      "metadata": {
        "id": "PqT1spMNX0Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RBM:\n",
        "  def __init__(self, n_visible, n_hidden, k=1, learning_rate=0.0001):\n",
        "    # number of input neurons (in MNIST pixels of an image --> 28x28 = 784)\n",
        "    self.n_visible = n_visible\n",
        "    # number of hidden units (it's an hyperparameter)\n",
        "    self.n_hidden = n_hidden\n",
        "    # number of Gibbs sampling steps for Contrastive Divergence (CD-k).\n",
        "    self.k = k\n",
        "    # step size for updating the weights and biases.\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "    # W is the weight matrix connecting visible to hidden units.\n",
        "    # Shape = n_hidden x n_visible. Initialized to Random small values\n",
        "    self.W = torch.randn(n_hidden, n_visible) * 0.01  # weight matrix\n",
        "    self.h_bias = torch.zeros(n_hidden)               # hidden bias\n",
        "    self.v_bias = torch.zeros(n_visible)              # visible bias\n",
        "\n",
        "    # Initialize momentum terms\n",
        "    self.W_momentum = torch.zeros_like(self.W)\n",
        "    self.h_bias_momentum = torch.zeros_like(self.h_bias)\n",
        "    self.v_bias_momentum = torch.zeros_like(self.v_bias)\n",
        "\n",
        "\n",
        "  # Sample hidden units given visible units\n",
        "  # params: v is a batch of visible units\n",
        "  def sample_h(self, v):\n",
        "        # computes wx that is the weighthed sum + bias for hidden units\n",
        "        wx = torch.matmul(v, self.W.t()) + self.h_bias\n",
        "        # computes probability of activation\n",
        "        prob = torch.sigmoid(wx)\n",
        "        # returns probabilities and sampled binary activations (0 or 1)\n",
        "        return prob, torch.bernoulli(prob)\n",
        "\n",
        "  # Sample visible units given hidden units\n",
        "  # Reverse of sample_h. Given hidden units, reconstruct visible units\n",
        "  # Returns probabilities + samples for visible layer\n",
        "  def sample_v(self, h):\n",
        "        wx = torch.matmul(h, self.W) + self.v_bias\n",
        "        prob = torch.sigmoid(wx)\n",
        "        return prob, torch.bernoulli(prob)\n",
        "\n",
        "  def contrastive_divergence(self, v0, momentum=0.0):\n",
        "        # start with input v0 (original data/training example)\n",
        "        v = v0\n",
        "        # run k steps of Gibbs sampling\n",
        "        # sample h from v, then v from h, repeatedly\n",
        "        # this gives the model's approximation of the input data (its \"fantasy\" or \"dream\")\n",
        "        for _ in range(self.k):\n",
        "            ph, h = self.sample_h(v)\n",
        "            pv, v = self.sample_v(h)\n",
        "\n",
        "        # Positive and negative phases\n",
        "        # positive phase: compute hidden activations from original input\n",
        "        ph0, h0 = self.sample_h(v0)\n",
        "        # negative phase: compute hidden activations from model-generated (sampled) input after k steps.\n",
        "        phk, hk = self.sample_h(v)\n",
        "\n",
        "        # Update weights and biases using the difference between positive and negative phases\n",
        "        # intuition: update weights and biases using the difference between positive and negative phases\n",
        "        # self.W += self.learning_rate * (torch.matmul(h0.t(), v0) - torch.matmul(hk.t(), v))\n",
        "        # self.v_bias += self.learning_rate * torch.sum(v0 - v, dim=0)\n",
        "        # self.h_bias += self.learning_rate * torch.sum(h0 - hk, dim=0)\n",
        "\n",
        "        batch_size = v0.size(0)\n",
        "        dW = (torch.matmul(h0.t(), v0) - torch.matmul(hk.t(), v)) / batch_size\n",
        "        dvb = torch.sum(v0 - v, dim=0) / batch_size\n",
        "        dhb = torch.sum(h0 - hk, dim=0) / batch_size\n",
        "\n",
        "        # Apply momentum update\n",
        "        self.W_momentum = momentum * self.W_momentum + self.learning_rate * dW\n",
        "        self.v_bias_momentum = momentum * self.v_bias_momentum + self.learning_rate * dvb\n",
        "        self.h_bias_momentum = momentum * self.h_bias_momentum + self.learning_rate * dhb\n",
        "\n",
        "        self.W += self.W_momentum\n",
        "        self.v_bias += self.v_bias_momentum\n",
        "        self.h_bias += self.h_bias_momentum\n",
        "\n",
        "  def initialize_visible_bias(self, train_loader):\n",
        "        \"\"\"\n",
        "        Estimate p_i (activation probability) for each visible unit and set visible bias accordingly.\n",
        "        \"\"\"\n",
        "        total = 0\n",
        "        sum_activations = torch.zeros(self.n_visible)\n",
        "\n",
        "        for batch, _ in train_loader:\n",
        "            batch = batch.view(-1, self.n_visible)\n",
        "            batch = (batch > 0.5).float()\n",
        "            sum_activations += torch.sum(batch, dim=0)\n",
        "            total += batch.size(0)\n",
        "\n",
        "        pi = sum_activations / total\n",
        "        pi = torch.clamp(pi, min=1e-5, max=1 - 1e-5)  # avoid log(0)\n",
        "\n",
        "        self.v_bias = torch.log(pi / (1 - pi))\n",
        "\n",
        "  def train(self, train_loader, use_momentum=True, n_epochs=5):\n",
        "    self.initialize_visible_bias(train_loader)\n",
        "\n",
        "    momentum = 0.5\n",
        "    prev_loss = float('inf')\n",
        "    trigger_epoch = n_epochs // 3  # when to switch to higher momentum\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        loss = 0\n",
        "        for images, _ in train_loader:\n",
        "            images = images.view(-1, self.n_visible)\n",
        "            images = (images > 0.5).float()\n",
        "            self.contrastive_divergence(images, momentum=momentum if use_momentum else 0.0)\n",
        "            loss += torch.mean((images - self.reconstruct(images)) ** 2).item()\n",
        "\n",
        "        avg_loss = loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.6f}, Momentum: {momentum:.2f}, LR: {self.learning_rate:.6f}\")\n",
        "\n",
        "        # Momentum scheduling\n",
        "        if use_momentum and epoch == trigger_epoch:\n",
        "            print(\"↑ Increasing momentum to 0.9\")\n",
        "            momentum = 0.9\n",
        "\n",
        "        # Instability detection: if error increases a lot\n",
        "        if use_momentum and epoch > trigger_epoch and avg_loss > prev_loss * 1.2:\n",
        "            print(\"⚠️ Instability detected. Reducing learning rate by 2.\")\n",
        "            self.learning_rate /= 2\n",
        "            momentum = 0.5  # Reset momentum if needed\n",
        "            print(f\"New learning rate: {self.learning_rate:.6f}\")\n",
        "\n",
        "        prev_loss = avg_loss\n",
        "\n",
        "  def reconstruct(self, v):\n",
        "      prob_h, h = self.sample_h(v)\n",
        "      prob_v, v_sample = self.sample_v(prob_h)\n",
        "      return prob_v\n",
        "\n",
        "  def encode(self, v):\n",
        "      prob_h, _ = self.sample_h(v)\n",
        "      return prob_h\n",
        "\n",
        "  def show_learnt_features(self, num_features=100):\n",
        "    \"\"\"\n",
        "    Visualize learned features (rows of weight matrix) as 28x28 images.\n",
        "    \"\"\"\n",
        "\n",
        "    # Clamp number of features to number of hidden units\n",
        "    num_features = min(num_features, self.n_hidden)\n",
        "    grid_size = int(np.ceil(np.sqrt(num_features)))\n",
        "\n",
        "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(8, 8))\n",
        "    for idx in range(num_features):\n",
        "        row = idx // grid_size\n",
        "        col = idx % grid_size\n",
        "        ax = axes[row, col]\n",
        "        weight_img = self.W[idx].detach().numpy().reshape(28, 28)\n",
        "        ax.imshow(weight_img, cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "    for i in range(num_features, grid_size * grid_size):\n",
        "        axes[i // grid_size, i % grid_size].axis('off')\n",
        "\n",
        "    plt.suptitle(\"Learned Features\", fontsize='x-large')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WSLlckAEX_mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_visible = 28 * 28\n",
        "n_hidden = 512\n",
        "\n",
        "# RBM with K=1\n",
        "rbm_k1 = RBM(n_visible=n_visible, n_hidden=n_hidden, k=1)\n",
        "rbm_k1.train(train_loader, n_epochs=5)\n",
        "rbm_k1.show_learnt_features()\n",
        "\n",
        "# RBM with K=5\n",
        "rbm_k5 = RBM(n_visible=n_visible, n_hidden=n_hidden, k=5)\n",
        "rbm_k5.train(train_loader, n_epochs=5)\n",
        "rbm_k5.show_learnt_features()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_Wuo70diSBR",
        "outputId": "40899e29-8121-4895-cba3-53b2448b30fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.085615, Momentum: 0.50, LR: 0.000100\n",
            "Epoch 2, Loss: 0.085505, Momentum: 0.50, LR: 0.000100\n",
            "↑ Increasing momentum to 0.9\n",
            "Epoch 3, Loss: 0.084878, Momentum: 0.90, LR: 0.000100\n",
            "Epoch 4, Loss: 0.081116, Momentum: 0.90, LR: 0.000100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_encoded_features(rbm, data_loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader:\n",
        "            images = images.view(-1, 28*28)\n",
        "            images = (images > 0.5).float()\n",
        "            encoded = rbm.encode(images)\n",
        "            features.append(encoded.numpy())\n",
        "            labels.append(targets.numpy())\n",
        "    return np.vstack(features), np.hstack(labels)\n",
        "\n",
        "X_train_k1, y_train_k1 = get_encoded_features(rbm_k1, train_loader)\n",
        "X_test_k1, y_test_k1 = get_encoded_features(rbm_k1, test_loader)\n",
        "\n",
        "X_train_k5, y_train_k5 = get_encoded_features(rbm_k5, train_loader)\n",
        "X_test_k5, y_test_k5 = get_encoded_features(rbm_k5, test_loader)"
      ],
      "metadata": {
        "id": "t5nexA02sYx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Classifier for RBM with k=1 ---\n",
        "clf_k1 = LogisticRegression(max_iter=1000)\n",
        "clf_k1.fit(X_train_k1, y_train_k1)\n",
        "\n",
        "# Predictions\n",
        "train_pred_k1 = clf_k1.predict(X_train_k1)\n",
        "test_pred_k1 = clf_k1.predict(X_test_k1)\n",
        "\n",
        "# Accuracy\n",
        "train_acc_k1 = accuracy_score(y_train_k1, train_pred_k1)\n",
        "test_acc_k1 = accuracy_score(y_test_k1, test_pred_k1)\n",
        "\n",
        "# --- Classifier for RBM with k=5 ---\n",
        "clf_k5 = LogisticRegression(max_iter=1000)\n",
        "clf_k5.fit(X_train_k5, y_train_k5)\n",
        "\n",
        "train_pred_k5 = clf_k5.predict(X_train_k5)\n",
        "test_pred_k5 = clf_k5.predict(X_test_k5)\n",
        "\n",
        "train_acc_k5 = accuracy_score(y_train_k5, train_pred_k5)\n",
        "test_acc_k5 = accuracy_score(y_test_k5, test_pred_k5)\n",
        "\n",
        "# Print results\n",
        "print(f\"RBM k=1 - Train Accuracy: {train_acc_k1 * 100:.2f}% | Test Accuracy: {test_acc_k1 * 100:.2f}%\")\n",
        "print(f\"RBM k=5 - Train Accuracy: {train_acc_k5 * 100:.2f}% | Test Accuracy: {test_acc_k5 * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "fVhsI0_Bsf-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(['K=1', 'K=5'], [test_acc_k1, test_acc_k5])\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Classifier accuracy for different CD(K) values\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b9TxVGz1spy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_rbm_with_hidden_activations(rbm, test_loader, n_digits=10):\n",
        "    digit_samples = {}\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            for img, lbl in zip(images, labels):\n",
        "                lbl = lbl.item()\n",
        "                if lbl not in digit_samples:\n",
        "                    digit_samples[lbl] = img\n",
        "                if len(digit_samples) == n_digits:\n",
        "                    break\n",
        "            if len(digit_samples) == n_digits:\n",
        "                break\n",
        "\n",
        "    fig, axs = plt.subplots(nrows=3, ncols=n_digits, figsize=(n_digits * 1.8, 5.5))\n",
        "    fig.suptitle(\"Original (Top), Reconstructed (Middle), Hidden Activations (Bottom)\", fontsize=14)\n",
        "\n",
        "    for i in range(n_digits):\n",
        "        img = digit_samples[i]\n",
        "        img_flat = img.view(-1).unsqueeze(0)\n",
        "        binary_img = (img_flat > 0.5).float()\n",
        "\n",
        "        # Encode to get binary sample instead of probabilities\n",
        "        _, encoded = rbm.sample_h(binary_img)\n",
        "        hidden_activations = encoded.squeeze().numpy()  # values will be 0 or 1\n",
        "        hidden_img = hidden_activations.reshape(16, 32)  # or (32, 16)\n",
        "        reconstructed = rbm.reconstruct(binary_img).view(28, 28).numpy()\n",
        "        hidden_activations = encoded.squeeze().numpy()\n",
        "\n",
        "        # Original image\n",
        "        axs[0, i].imshow(img.squeeze(), cmap='gray')\n",
        "        axs[0, i].axis('off')\n",
        "        axs[0, i].set_title(f\"Digit {i}\")\n",
        "\n",
        "        # Reconstructed image\n",
        "        axs[1, i].imshow(reconstructed, cmap='gray')\n",
        "        axs[1, i].axis('off')\n",
        "\n",
        "        # Hidden activations as heatmap (reshape for visual effect if possible)\n",
        "        axs[2, i].imshow(hidden_img, cmap='gray')  # or 'binary' or 'hot'\n",
        "        axs[2, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "db_5tcIitUYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_rbm_with_hidden_activations(rbm_k1, test_loader)"
      ],
      "metadata": {
        "id": "J8JOT2u-tZM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_embedding(X, y, method='pca', title=''):\n",
        "    if method == 'pca':\n",
        "        reducer = PCA(n_components=2)\n",
        "    elif method == 'tsne':\n",
        "        reducer = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=42)\n",
        "    else:\n",
        "        raise ValueError(\"Method must be 'pca' or 'tsne'\")\n",
        "\n",
        "    X_embedded = reducer.fit_transform(X)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(x=X_embedded[:, 0], y=X_embedded[:, 1], hue=y, palette=\"tab10\", s=15, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.legend(title='Digit', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_embedding(X_test_k1, y_test_k1, method='pca', title='RBM K=1 - PCA')\n",
        "plot_embedding(X_test_k1, y_test_k1, method='tsne', title='RBM K=1 - t-SNE')\n",
        "\n",
        "plot_embedding(X_test_k5, y_test_k5, method='pca', title='RBM K=5 - PCA')\n",
        "plot_embedding(X_test_k5, y_test_k5, method='tsne', title='RBM K=5 - t-SNE')"
      ],
      "metadata": {
        "id": "Bf0sb-_ErLB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_denoising(rbm, test_loader, digit=2, steps=10, noise_level=0.4):\n",
        "    # Step 1: Get one sample of the desired digit\n",
        "    for image, label in test_loader:\n",
        "        mask = (label == digit)\n",
        "        if mask.any():\n",
        "            original_img = image[mask][0].view(1, -1)\n",
        "            break\n",
        "\n",
        "    # Step 2: Binarize and add noise\n",
        "    original_img = (original_img > 0.5).float()\n",
        "    noisy_img = original_img.clone()\n",
        "    noise = torch.bernoulli(torch.full_like(noisy_img, noise_level))\n",
        "    noisy_img = (noisy_img + noise) % 2  # flip bits with probability = noise_level\n",
        "\n",
        "    # Store reconstructions\n",
        "    reconstructions = [noisy_img.view(28, 28).numpy()]\n",
        "    v = noisy_img.clone()\n",
        "\n",
        "    # Step 3: Perform multiple Gibbs steps\n",
        "    for _ in range(steps):\n",
        "        prob_h, h = rbm.sample_h(v)\n",
        "        prob_v, v = rbm.sample_v(h)\n",
        "        reconstructions.append(prob_v.view(28, 28).detach().numpy())\n",
        "\n",
        "    # Step 4: Plot everything\n",
        "    n_cols = steps + 2\n",
        "    fig, ax = plt.subplots(1, n_cols, figsize=(2.5 * n_cols, 3))\n",
        "\n",
        "    ax[0].imshow(original_img.view(28, 28).numpy(), cmap=\"gray\")\n",
        "    ax[0].set_title(\"Original\")\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    ax[1].imshow(reconstructions[0], cmap=\"gray\")\n",
        "    ax[1].set_title(f\"Noisy (p={noise_level})\")\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    for i in range(1, steps + 1):\n",
        "        ax[i + 1].imshow(reconstructions[i], cmap=\"gray\")\n",
        "        ax[i + 1].set_title(f\"Step {i}\")\n",
        "        ax[i + 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SgrOMB2Lvbfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_denoising(rbm_k5, test_loader, digit=7, steps=20, noise_level=0.1)\n"
      ],
      "metadata": {
        "id": "Q2oidhiJvexS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}